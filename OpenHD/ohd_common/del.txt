// A UDP Wifibroadcast stream is a directional lossy connection between
// two units that support wifibroadcast, for example the OpenHD air pi and the OpenHD ground pi.
// It is specified by the following values:
struct XUDPWifibroadcastStream{
    // Set this to true if the stream goes from the air pi to the ground pi.
    // Otherwise, the stream goes from the ground pi to the air pi.
    // Depending on this value, the air pi (and ground pi respective) create
    // either a transmitting wifibroadcast instance or a receiving wifibroadcast intance.
    bool fromAirPiToGroundPi;
    // each UDP wifibroadcast stream has a unique radio port. To avoid clashes, all streams in OpenHD
    // (no matter the direction) have to use distinct radio ports.
    uint8_t rf_radio_port;
    // A UDP WB TX instance listens on a specific localhost udp port while
    // a UDP WB RX instance sends the received data to a specific localhost udp port.
    int udp_localhost_input_port;
    int udp_localhost_output_port;
};

// For OpenHD Telemetry
// Note that the ports for the air and ground are just reversed - this way, one can either run
// the telemetry service on the same system in 2 instances and they talk to each other,
// or run it on 2 different systems with wifibroadcast in between.
static constexpr XUDPWifibroadcastStream OHD_TELEMETRY_AIR_TO_GROUND{true,0,16550,16551};
static constexpr XUDPWifibroadcastStream OHD_TELEMETRY_GROUND_TO_AIR{false,1,16551,16550};

// For OpenHD Video
// Note that the udp ports on the air and ground side match each other.
// Since all video transmission is unidirectional, we can get away with this. It makes debugging easier (in my opinion),
// aka for debugging one could theoretically just start QOpenHD on the air pi lol ;).
// TODO: Do we really need more than 2 video stream(s) ?!! I don't think so, there is no bandwidth for more anyways.
// Also, In case someone has more than 2 cameras connected, the best would probably be to have the option to dynamically
// assign camera X to the primary video stream.
static constexpr XUDPWifibroadcastStream OHD_VIDEO_1_PRIMARY{true,10,5620,5620};
static constexpr XUDPWifibroadcastStream OHD_VIDEO_2_SECONDARY{true,11,5621,5621};


// CSI cameras don't have an endpoint,
// Since there are too many specialities as if we could generify them.
// Also, in case of CIS cameras, we don't need the raw stuff, since pretty much every
// CSI camera then has a custom hw-accelerated pipeline that produces H264/H265/MJPEG out.
// However, a UVC camera might have YUV and/or MJPEG out and requires custom encoding.
struct UvcCameraEndpoint {
  std::string device_node;
};

// A raw endpoint is for cameras that support YUV or RGB raw frames.
// Most likely, the stream is then going to do sw encoding on them.
// This way, we can handle thermal cameras for example.
struct RawEndpoint {
  std::string device_node;
  std::string bus;
  std::vector<std::string> supportedRawFormats;
};

// An encoded endpoint is for cameras that support h264,h265 or MJPEG.
// This is mostly for CSI cameras, for which we then later have a HW accelerated method
// Of generating an encoded video stream that doesn't directly talk to the underlying v4l2 device node,
// but rather uses somthing else (raspivid or libcamera, as an example).
// However, some UVC cameras also support directly encoded MJPEG or h264/h265 out. In this case, they get a encoded endpoint,too.
struct EncodedEndpoint {
  // A list of all the video formats this camera can do for generating encoded data.
  // If the list of supported formats is empty, one can assume that the camera can do anything ?
  // TODO: Or should we make it a hard requirement, and what we as develoers have not said is "feasible" for the camera
  // is all it can do ?
  std::vector<VideoFormat> supportedFormats;
};

/**
   * Convert a readable video format string into a type-safe video format.
   * @param input the string, for example as generated above.
   * @return the video format, with the parsed values from above. On failure,
   * behaviour is undefined.
   * Note: For debugging, I use https://regex101.com/
   */
  static VideoFormat fromString(const std::string &input) {
    // We default to values that are most likely going to work, in case parsing
    // fails.
    VideoFormat ret{};
    std::smatch result;
    const std::regex reg{R"(([\w\d\s\-\:\/]*)\|(\d*)x(\d*)\@(\d*))"};
    std::cout << "Parsing:" << input << std::endl;
    if (std::regex_search(input, result, reg)) {
      if (result.size() == 5) {
        ret.videoCodec = string_to_video_codec(result[1]);
        ret.width = atoi(result[2].str().c_str());
        ret.height = atoi(result[3].str().c_str());
        ret.framerate = atoi(result[4].str().c_str());
        std::cout << "Parsed:" << ret.toString() << "\n";
      } else {
        std::cout << "Video format missmatch " << result.size();
        for (int a = 0; a < result.size(); a++) {
          std::cout << " " << a << " " << result[a] << ".";
        }
        std::cout << std::endl;
      }
    } else {
      std::cerr << "Video regex format failed " << input << "\n";
    }
    return ret;
  }


static VideoCodec string_to_video_codec(const std::string &codec) {
  if (OHDUtil::to_uppercase(codec).find(OHDUtil::to_uppercase("h264")) !=
      std::string::npos) {
    return VideoCodec::H264;
  } else if (OHDUtil::to_uppercase(codec).find(OHDUtil::to_uppercase("h265")) !=
             std::string::npos) {
    return VideoCodec::H265;
  } else if (OHDUtil::to_uppercase(codec).find(
                 OHDUtil::to_uppercase("mjpeg")) != std::string::npos) {
    return VideoCodec::MJPEG;
  }
  return VideoCodec::Unknown;
}
static WiFiHotspotType string_to_wifi_hotspot_type(const std::string &hotspot_type) {
  if (OHDUtil::to_uppercase(hotspot_type).find(OHDUtil::to_uppercase("internal2g")) != std::string::npos) {
	return WiFiHotspotType::Internal2GBand;
  } else if (OHDUtil::to_uppercase(hotspot_type).find(OHDUtil::to_uppercase("internal5g")) != std::string::npos) {
	return WiFiHotspotType::Internal5GBand;
  } else if (OHDUtil::to_uppercase(hotspot_type).find(OHDUtil::to_uppercase("internaldualband")) != std::string::npos) {
	return WiFiHotspotType::InternalDualBand;
  } else if (OHDUtil::to_uppercase(hotspot_type).find(OHDUtil::to_uppercase("external")) != std::string::npos) {
	return WiFiHotspotType::External;
  }
  return WiFiHotspotType::None;
}
static WifiUseFor wifi_use_for_from_string(const std::string s){
  if(OHDUtil::to_uppercase(s).find(OHDUtil::to_uppercase("monitor_mode"))!=std::string::npos){
	return WifiUseFor::MonitorMode;
  }else if(OHDUtil::to_uppercase(s).find(OHDUtil::to_uppercase("hotspot"))!=std::string::npos){
	return WifiUseFor::Hotspot;
  }else{
	return WifiUseFor::Unknown;
  }
}

/**
 * The settings are stored in a directory called air_$unit_id or ground_$unit_id.
 * @return the settings directory, created newly if non existent. As an example, it will return a path like
 * this: BASE_PATH/air_8bfff348-c17e-4833-af66-cef83f90c208/
 */
static std::string findOrCreateSettingsDirectory(bool is_air) {
  generateSettingsDirectoryIfNonExists();
  std::stringstream settingsPath;
  settingsPath << BASE_PATH;
  settingsPath << (is_air ? "air_" : "ground_");
  const auto unit_id = getOrCreateUnitId();
  settingsPath << unit_id;
  auto str = settingsPath.str();
  std::cout << "SettingsDirectory:[" << str << "]\n";
  // create the directory if it is non existing
  if (!std::filesystem::exists(str.c_str())) {
	std::filesystem::create_directory(str.c_str());
  }
  assert(std::filesystem::exists(str.c_str()));
  return str;
}
static void create_directory_if_not_existing(const char* directory){
  if(!exists(directory)){
	create_directory(directory);
  }
}